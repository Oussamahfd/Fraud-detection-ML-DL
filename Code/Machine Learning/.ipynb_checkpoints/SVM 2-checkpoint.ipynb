{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96ae19d6-21fb-418e-a7e5-63bfa1eb6f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d658bf0-71d0-432d-863e-2203427c8658",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data =pd.read_csv('C:/Users/PC/Desktop/2/pfa/Datasets/Credit Card Transactions Fraud Detection Dataset/fraudTrain.csv')\n",
    "test_data = pd.read_csv('C:/Users/PC/Desktop/2/pfa/Datasets/Credit Card Transactions Fraud Detection Dataset/fraudTest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "380a3594-956c-46d4-b860-2f08c33c044f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1296675, 23)\n",
      "(555719, 23)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5956595-e46c-4a28-b2b7-0d40e0f66f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.dropna(inplace=True)\n",
    "test_data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "204e63b3-ab5a-44e4-b32d-edacf6b68774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1296675, 23)\n",
      "(555719, 23)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29590445-a8d3-4817-97fd-cb4e321197b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time analysis: Extract hours and days from 'trans_date_trans_time'\n",
    "train_data['trans_hour'] = pd.to_datetime(train_data['trans_date_trans_time']).dt.hour\n",
    "train_data['trans_day'] = pd.to_datetime(train_data['trans_date_trans_time']).dt.dayofweek\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a28f5ef9-c80a-4576-9a1d-cea9f1138e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['trans_date_trans_time'] = pd.to_datetime(train_data['trans_date_trans_time'])\n",
    "train_data['trans_date'] = train_data['trans_date_trans_time'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23dc69ee-d9d2-4938-a166-6b608f51ffb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['time_since_last_transaction'] = train_data.groupby('cc_num')['unix_time'].diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12b30ffc-983a-4267-90f8-769beb15abf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['dob'] = pd.to_datetime(train_data['dob'])\n",
    "train_data['age'] = (train_data['trans_date_trans_time'] - train_data['dob']).dt.days // 365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d4b1f0c-42a4-4752-84bf-c1d8b6a0adf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['trans_hour'] = pd.to_datetime(train_data['trans_date_trans_time']).dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a4bb32f-a605-4461-a7ac-944b6d3add0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7601edef-18ff-4b74-9fc7-974eb32ad3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables\n",
    "encoder = OneHotEncoder(drop='first')\n",
    "categorical_cols = ['gender', 'category', 'state']\n",
    "encoded_train_features = encoder.fit_transform(train_data[categorical_cols]).toarray()\n",
    "encoded_test_features = encoder.transform(test_data[categorical_cols]).toarray()\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "numerical_cols = ['amt', 'lat', 'long','city_pop', 'unix_time', 'merch_lat', 'merch_long']\n",
    "scaled_train_features = scaler.fit_transform(train_data[numerical_cols])\n",
    "scaled_test_features = scaler.transform(test_data[numerical_cols])\n",
    "\n",
    "\n",
    "# Concatenate encoded and scaled features for both train and test data\n",
    "final_train_features = pd.concat([pd.DataFrame(encoded_train_features), pd.DataFrame(scaled_train_features)], axis=1)\n",
    "final_test_features = pd.concat([pd.DataFrame(encoded_test_features), pd.DataFrame(scaled_test_features)], axis=1)\n",
    "\n",
    "# Define target variables\n",
    "train_target = train_data['is_fraud']\n",
    "test_target = test_data['is_fraud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9bff5e7d-cff3-4f75-9509-11f71feca6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating synthetic data to balance the imbalanced dataset\n",
    "smote = SMOTE(random_state=36)\n",
    "\n",
    "x_train_resample, y_train_resample = smote.fit_resample(final_train_features, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a625d65e-2aa6-4d43-9e15-c4c270d026d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_shuffled, y_shuffled = shuffle(x_train_resample, y_train_resample, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "100ac4b1-d59f-477a-9b65-d79dfeb666f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_validation, y_train, y_validation = train_test_split(X_shuffled, y_shuffled, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "78a3490e-643b-45d8-a99d-d0aeb51cdc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the initial selection process we will use a tiny\n",
    "# portion of the actual training dataset\n",
    "x_train_copy = x_train\n",
    "y_train_copy = y_train\n",
    "\n",
    "x_train = x_train[:10000]\n",
    "y_train = y_train[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6dea7a1a-e09a-4bf9-bf2f-1fea8b220450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 86.023%\n"
     ]
    }
   ],
   "source": [
    "# Train SVM model\n",
    "from sklearn.svm import SVC\n",
    "svm_model = SVC(kernel='poly')\n",
    "svm_model.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions on test data\n",
    "svm_predictions = svm_model.predict(x_validation)\n",
    "\n",
    "# Calculate evaluation metrics on test data\n",
    "svm_accuracy = accuracy_score(y_validation, svm_predictions)\n",
    "\n",
    "\n",
    "# Print evaluation metrics with 3 decimal places, multiplied by 100\n",
    "print(\"SVM Accuracy: {:.3f}%\".format(svm_accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30958c7-e4bf-417a-a444-5803639434b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate decision scores for the positive class\n",
    "decision_scores = svm_model.decision_function(final_test_features)\n",
    "\n",
    "# Calculate ROC curve and AUC\n",
    "fpr, tpr, thresholds = roc_curve(test_target, decision_scores)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ef099c-de84-4eec-8868-815976b73bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and plot confusion matrix\n",
    "conf_matrix = confusion_matrix(y_validation, svm_predictions)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
